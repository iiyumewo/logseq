- # 为什么需要
- 系统的用户使用情况、线上异常情况、设备分布情况、营销活动的 PV/UV 转化情况统统一无所知
- **“工具为王效率至上” 的技术价值观**
- 1. 量化标准
  2. 线上问题有的放矢
-
- # 选择自研
- 1. 价格
  2. 与错误监控平台竞品的分析对比 Sentry BugSnag Fundebug Bugly FrontJS
  4. 结合自身业务的量级，追求稳定性、可拓展性、安全性、成本这些因素
-
- # 架构设计
- 1. 应用接入
  2. 数据收集
  3. 数据清洗与持久化
  4. 数据服务
  5. 数据可视化
-
- 一、应用接入部分：
- 零成本接入
- 多端(当前仅在构筑上留出易于扩展的空间)
-
- 二、数据收集部分：
-
-
- 三、数据清洗与持久化部分：
- 基于当前的项目数量、用户量与数据量，预估数据量不大，所以可以暂时无需清洗数据
- 数据特征：
- 1. 数据量大体积大，可能来自于网络波动用户积累的数据上传
  2. 缺乏分类、聚合，同一类错误的 stack trace 完全一致，仅仅在时间维度上、客户端信息上有区别，对存储造成了压力
-
- 从队列或预处理库中取出单位时间(例如1分钟)的数据进行数据清洗，随后入库
- 削峰应该从两个环节进行限制
- 1. 网关层将适当拒绝超过设定阈值的入库请求，例如在严重线上事故的场景下，可能所有客户端均会提交报错，对服务器形成巨大压力。我们会设置一个单位时间最大接收的阈值，超过的部分全部丢弃，或利用令牌桶方案在时间维度上进行采样收集。
- 2. 数据清洗层是 cpu 密集型场景，同样为了降低服务器压力，我们也会设定一个阈值，单位时间超过处理阈值的数据，要么丢弃，要么采样后丢弃。
-
- 入库前对数据进行 json 格式化及删减不必要的垃圾信息
- 数据聚合：
- 数据聚合将大大减小存储量，在持久化存储中单位时间内多条相同报错将会被聚合为以报错数量为核心的单条数据
- 数据聚合的标准：
- 以报错内容及 stack trace 的 hash 值为标准，hash 相同则判定为同一报错
-
- 清洗过程的监控：
- 如上所述，数据清洗的过程中，为了系统的稳定性及安全性，我们在必要的场合势必会抛弃一些数据，被忽略的数据数量也需要记录下来，这也是在问题回溯中一个重要的参考标准。接收数据量和耗时、忽略数据量、每分钟处理量这三个数据可以衡量监控业务的稳定性，如果某时间段出现大的波动，其中的出现的错误排查可能需要重点关注。
-
- 收集到的错误如何通过 sourcemap 进行源码定位
-
- # 技术选型
-